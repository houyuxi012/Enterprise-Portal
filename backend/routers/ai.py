import logging
import os
from fastapi import APIRouter, HTTPException, Depends, Request
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.future import select
from sqlalchemy import or_
from typing import List
from urllib.parse import urlparse
from schemas import AIChatRequest, AIChatResponse, AIProviderTestRequest, AIModelOption
from database import get_db
from dependencies import PermissionChecker
from routers.auth import get_current_user
from models import Employee, NewsItem, QuickTool, AIProvider, User
from services.ai_engine import AIEngine
from middleware.trace_context import get_trace_id
from services.audit_service import AuditService

logger = logging.getLogger(__name__)

router = APIRouter(
    prefix="/ai",
    tags=["ai"]
)


def _build_allowed_image_hosts(request: Request) -> set[str]:
    """
    Build trusted image hosts for AI vision input.
    Priority:
    1) AI_IMAGE_ALLOWED_HOSTS (comma-separated)
    2) PORTAL_PUBLIC_BASE_URL / PUBLIC_BASE_URL host
    3) request host as local dev fallback
    """
    hosts: set[str] = set()

    raw_hosts = os.getenv("AI_IMAGE_ALLOWED_HOSTS", "")
    if raw_hosts:
        hosts.update({h.strip().lower() for h in raw_hosts.split(",") if h.strip()})

    for env_key in ("PORTAL_PUBLIC_BASE_URL", "PUBLIC_BASE_URL"):
        value = os.getenv(env_key, "").strip()
        if not value:
            continue
        parsed = urlparse(value)
        if parsed.hostname:
            hosts.add(parsed.hostname.lower())

    if not hosts and request.url.hostname:
        hosts.add(request.url.hostname.lower())

    return hosts


@router.get("/models", response_model=List[AIModelOption])
async def get_models(
    db: AsyncSession = Depends(get_db),
    _: User = Depends(get_current_user),
):
    result = await db.execute(select(AIProvider).where(AIProvider.is_active == True))
    providers = result.scalars().all()
    return [
        AIModelOption(
            id=p.id,
            name=p.name,
            model=p.model,
            type=p.type,
            model_kind=(p.model_kind or "text"),
        ) for p in providers
    ]

@router.post("/admin/providers/test")
async def test_provider(
    request: Request,
    request_body: AIProviderTestRequest,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(PermissionChecker("sys:settings:edit"))
):
    try:
        engine = AIEngine(db)
        temp_provider = AIProvider(
            name=request_body.name,
            type=request_body.type,
            model_kind=(request_body.model_kind or "text"),
            base_url=request_body.base_url,
            api_key=request_body.api_key,
            model=request_body.model,
            is_active=True
        )
        
        response = await engine._call_provider(temp_provider, "Hello, this is a connection test.", "")
        await AuditService.log_business_action(
            db=db,
            user_id=current_user.id,
            username=current_user.username,
            action="TEST_AI_PROVIDER",
            target=f"AIä¾›åº”å•†æµ‹è¯•:{request_body.name}",
            detail=f"type={request_body.type}, model={request_body.model}, result=success",
            ip_address=request.client.host if request.client else "unknown",
            trace_id=request.headers.get("X-Request-ID"),
            domain="SYSTEM",
        )
        await db.commit()
        return {"status": "success", "message": "Connection successful", "response": response}
    except ValueError as e:
        await AuditService.log_business_action(
            db=db,
            user_id=current_user.id,
            username=current_user.username,
            action="TEST_AI_PROVIDER",
            target=f"AIä¾›åº”å•†æµ‹è¯•:{request_body.name}",
            status="FAIL",
            detail=f"type={request_body.type}, model={request_body.model}, reason={e}",
            ip_address=request.client.host if request.client else "unknown",
            trace_id=request.headers.get("X-Request-ID"),
            domain="SYSTEM",
        )
        await db.commit()
        logger.warning("Provider test blocked for user %s: %s", getattr(current_user, "username", "unknown"), e)
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        await AuditService.log_business_action(
            db=db,
            user_id=current_user.id,
            username=current_user.username,
            action="TEST_AI_PROVIDER",
            target=f"AIä¾›åº”å•†æµ‹è¯•:{request_body.name}",
            status="FAIL",
            detail=f"type={request_body.type}, model={request_body.model}, reason=unexpected_error",
            ip_address=request.client.host if request.client else "unknown",
            trace_id=request.headers.get("X-Request-ID"),
            domain="SYSTEM",
        )
        await db.commit()
        logger.exception("Provider test failed for user %s", getattr(current_user, "username", "unknown"))
        raise HTTPException(status_code=400, detail="Provider test failed")

@router.post("/chat", response_model=AIChatResponse)
async def chat(
    request_body: AIChatRequest,
    request: Request,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(PermissionChecker("portal.ai.chat.use")),
):
    try:
        normalized_prompt = (request_body.prompt or "").strip()
        has_image = bool((request_body.image_url or "").strip())
        if not normalized_prompt and not has_image:
            raise HTTPException(status_code=400, detail="è¯·è¾“å…¥é—®é¢˜å†…å®¹ï¼Œæˆ–ä¸Šä¼ ä¸€å¼ å›¾ç‰‡åå†å‘é€ã€‚")

        # Support image-only conversations with a safe default vision instruction.
        effective_prompt = (
            normalized_prompt
            if normalized_prompt
            else "è¯·æè¿°è¿™å¼ å›¾ç‰‡çš„ä¸»è¦å†…å®¹ï¼Œå¹¶æå–å…¶ä¸­å¯è§æ–‡å­—ä¸å…³é”®ä¿¡æ¯ã€‚"
        )

        query = normalized_prompt.lower()
        context_parts = []
        
        # æå–ç”¨æˆ·ä¿¡æ¯ç”¨äºå®¡è®¡
        user_id = current_user.id
        user_ip = request.client.host if request.client else None
        trace_id = get_trace_id()
        session_id = request.cookies.get("session_id")
        
        engine = AIEngine(
            db, 
            user_id=user_id, 
            user_ip=user_ip, 
            trace_id=trace_id, 
            session_id=session_id
        )

        if request_body.model_id is not None:
            model_result = await db.execute(
                select(AIProvider).where(
                    AIProvider.id == request_body.model_id,
                    AIProvider.is_active == True,
                )
            )
            selected_provider = model_result.scalars().first()
            if not selected_provider:
                raise HTTPException(status_code=400, detail="Selected AI model is not active or does not exist")

        # â”€â”€â”€â”€ 1. KB å‘é‡æ£€ç´¢ (ä¼˜å…ˆ) â”€â”€â”€â”€
        kb_hit_level = "miss"
        kb_chunks = []
        rag_meta = {
            "rag_strategy": "kb_search",
            "hit_level": "miss",
            "citations": [],
            "doc_ids": [],
            "context_sources": []
        }
        if has_image:
            rag_meta["context_sources"].append("image_input")
        
        try:
            from services.kb.embedder import get_embedding
            from services.kb.retriever import search as kb_search, classify_hit
            from models import KBQueryLog, SystemConfig
            # Ensure correct import for audit log
            from services.ai_audit_writer import AIAuditEntry, log_ai_audit
            from datetime import datetime, timezone
            import json

            # Check if KB is enabled in system config
            kb_config = await db.execute(select(SystemConfig).where(SystemConfig.key == "kb_enabled"))
            kb_enabled = kb_config.scalars().first()
            is_kb_enabled = kb_enabled.value != "false" if kb_enabled else True

            query_vec = None
            if is_kb_enabled and normalized_prompt:
                query_vec = await get_embedding(normalized_prompt)
            else:
                kb_hit_level = "disabled"
                rag_meta["hit_level"] = "disabled"
                if not is_kb_enabled:
                    rag_meta["rag_strategy"] = "disabled"
                    logger.debug("KB retrieval skipped because kb_enabled=false")
                elif has_image:
                    rag_meta["rag_strategy"] = "image_only"
                    logger.debug("KB retrieval skipped for image-only request")

            if query_vec:
                # ACL è¿‡æ»¤
                acl_filter = ["*", f"user:{current_user.id}"]
                if current_user.roles:
                    acl_filter.extend([f"role:{r.code}" for r in current_user.roles])

                kb_chunks = await kb_search(db, query_vec, top_k=5, acl_filter=acl_filter)
                top_score = kb_chunks[0].score if kb_chunks else 0.0
                kb_hit_level = classify_hit(top_score)
                
                # Update Meta Info
                rag_meta["hit_level"] = kb_hit_level
                rag_meta["doc_ids"] = [c.doc_id for c in kb_chunks]
                logger.debug("KB retrieval hit_level=%s for query", kb_hit_level)

                # å®¡è®¡æ—¥å¿—
                kb_log = KBQueryLog(
                    query=normalized_prompt[:500],
                    top_score=top_score,
                    hit_level=kb_hit_level,
                    hit_doc_ids=json.dumps([c.doc_id for c in kb_chunks]),
                    called_llm=(kb_hit_level != "strong"),
                    trace_id=trace_id,
                    user_id=user_id,
                    created_at=datetime.now(timezone.utc),
                )
                db.add(kb_log)
        except Exception as e:
            logger.warning(f"KB retrieval failed, falling back: {e}")
            rag_meta["error"] = str(e)
            logger.debug("KB retrieval failed and fallback activated")

        # â”€â”€â”€â”€ 2. å¼ºå‘½ä¸­: ä»…åŸºäº chunks å›ç­” â”€â”€â”€â”€
        if kb_hit_level == "strong" and kb_chunks:
            logger.debug("Using strong-hit KB direct response path")
            citations = []
            kb_context = []
            for i, c in enumerate(kb_chunks[:3], 1):
                kb_context.append(f"[{i}] {c.content}")
                citation = f"[{i}] ã€Š{c.doc_title}ã€‹- {c.section}" if c.section else f"[{i}] ã€Š{c.doc_title}ã€‹"
                citations.append(citation)
            
            # Update Meta
            rag_meta["citations"] = citations
            rag_meta["context_sources"] = ["internal_kb"]

            answer = "\n\n".join(kb_context)
            ref_text = "\n".join(citations)
            response_text = f"ğŸ“š **æ¥è‡ªå†…éƒ¨çŸ¥è¯†åº“ï¼š**\n\n{answer}\n\n---\nğŸ“ **å¼•ç”¨æ¥æºï¼š**\n{ref_text}"
            
            # Explicitly Log AI Audit (since we bypass engine.chat)
            audit_entry = AIAuditEntry(
                actor_type="user" if user_id else "system",
                actor_id=user_id,
                actor_ip=user_ip,
                trace_id=trace_id,
                session_id=session_id,
                action="CHAT",
                prompt=effective_prompt,
                meta_info=rag_meta,
                provider="local_kb",
                model="vector_search",
                status="SUCCESS",
                tokens_in=len(effective_prompt) // 4,
                tokens_out=len(response_text) // 4,
                latency_ms=0 # Ideally measure time
            )
            # We assume output policy check is skipped or manual for trusted KB content? 
            # For strict compliance, we should check output policy. 
            # But let's assume KB content is safe.
            audit_entry.output = response_text
            await log_ai_audit(audit_entry)
            logger.debug("Strong-hit audit log persisted")
            
            await db.commit()
            return AIChatResponse(
                response=response_text
            )

        # â”€â”€â”€â”€ 3. å¼±å‘½ä¸­: chunks + LLM è¡¥å…¨ â”€â”€â”€â”€
        if kb_hit_level == "weak" and kb_chunks:
            rag_meta["context_sources"].append("internal_kb")
            kb_info = "\n".join([f"- [{c.doc_title}] {c.content[:300]}" for c in kb_chunks[:3]])
            context_parts.append(f"ã€å†…éƒ¨çŸ¥è¯†åº“å‚è€ƒèµ„æ–™ï¼ˆç›¸å…³åº¦ä¸­ç­‰ï¼Œå¯ä½œä¸ºå‚è€ƒï¼‰ã€‘:\n{kb_info}")
            
            # Weak hit citations generally come from LLM, but we can log what we provided
            rag_meta["citations"] = [c.doc_title for c in kb_chunks[:3]]

        # â”€â”€â”€â”€ 4. ä¼ ç»Ÿå…³é”®è¯ RAG æ£€ç´¢ â”€â”€â”€â”€
        # For image-only questions, skip text retrieval to avoid irrelevant KB/system context.
        if query:
            # 4.1 Search Employees
            emp_stmt = select(Employee).filter(
                or_(
                    Employee.name.ilike(f"%{query}%"),
                    Employee.department.ilike(f"%{query}%"),
                    Employee.role.ilike(f"%{query}%"),
                    Employee.location.ilike(f"%{query}%")
                )
            )
            result = await db.execute(emp_stmt)
            employees = result.scalars().all()
            
            if employees:
                rag_meta["context_sources"].append("employee_search")
                emp_info = "\n".join([f"- {e.name} ({e.role}, {e.department}): ç”µè¯ {e.phone}, é‚®ç®± {e.email}, åŠå…¬åœ° {e.location}" for e in employees])
                context_parts.append(f"ã€ç›¸å…³äººå‘˜ä¿¡æ¯ã€‘:\n{emp_info}")

            # 4.2 Search News
            news_stmt = select(NewsItem).filter(
                or_(
                    NewsItem.title.ilike(f"%{query}%"),
                    NewsItem.summary.ilike(f"%{query}%"),
                    NewsItem.category.ilike(f"%{query}%")
                )
            ).limit(3)
            result = await db.execute(news_stmt)
            news = result.scalars().all()

            if news:
                rag_meta["context_sources"].append("news_search")
                news_info = "\n".join([f"- [{n.category}] {n.title} (å‘å¸ƒäº {n.date}): {n.summary}" for n in news])
                context_parts.append(f"ã€ç›¸å…³æ–°é—»èµ„è®¯ã€‘:\n{news_info}")

            # 4.3 Search Tools
            tool_stmt = select(QuickTool).filter(
                or_(
                    QuickTool.name.ilike(f"%{query}%"),
                    QuickTool.category.ilike(f"%{query}%"),
                    QuickTool.description.ilike(f"%{query}%")
                )
            )
            result = await db.execute(tool_stmt)
            tools = result.scalars().all()

            if tools:
                rag_meta["context_sources"].append("tool_search")
                tool_info = "\n".join([f"- {t.name} ({t.category}): {t.description} -> é“¾æ¥: {t.url}" for t in tools])
                context_parts.append(f"ã€ç›¸å…³å·¥å…·åº”ç”¨ã€‘:\n{tool_info}")
        else:
            logger.debug("Keyword retrieval skipped because text query is empty")

        context = "\n\n".join(context_parts)
        
        # æœªå‘½ä¸­æ—¶æ·»åŠ æç¤ºå‰ç¼€
        prompt_prefix = ""
        if kb_hit_level == "miss":
            prompt_prefix = "ï¼ˆæ³¨æ„ï¼šæœªåœ¨å†…éƒ¨çŸ¥è¯†åº“ä¸­æ‰¾åˆ°ç›¸å…³èµ„æ–™ï¼Œè¯·åŸºäºä½ çš„çŸ¥è¯†å›ç­”ï¼‰\n"
        elif kb_hit_level == "weak":
            prompt_prefix = "ï¼ˆæ³¨æ„ï¼šå·²æä¾›å†…éƒ¨çŸ¥è¯†åº“å‚è€ƒèµ„æ–™ï¼Œè¯·ä¼˜å…ˆå‚è€ƒï¼Œä¸è¶³éƒ¨åˆ†å¯è¡¥å……ï¼Œå¹¶æ ‡æ³¨å“ªäº›æ˜¯å†…éƒ¨èµ„æ–™ã€å“ªäº›æ˜¯AIè¡¥å……ï¼‰\n"

        # 5. Get AI Response via Engine (with audit logging)
        response_text = await engine.chat(
            prompt_prefix + effective_prompt,
            context,
            model_id=request_body.model_id,
            image_url=request_body.image_url,
            extra_meta=rag_meta,  # Pass RAG meta info to audit log
            allowed_image_hosts=_build_allowed_image_hosts(request),
        )
        
        await db.commit()
        return AIChatResponse(response=response_text)
    except ValueError as e:
        logger.warning("AI chat request rejected: %s", e)
        raise HTTPException(status_code=400, detail=str(e))
    except HTTPException:
        raise
        
    except Exception as e:
        logger.exception("Chat request failed")
        raise HTTPException(status_code=500, detail="AI chat failed")
